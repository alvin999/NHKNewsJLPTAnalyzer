import streamlit as st
import json
import os
import pandas as pd
from app.translator import translate_text
from app.analyzer import analyze_jlpt_level
import plotly.express as px
from backend.crawl import fetch_article_full_text

# 1. é é¢è¨­å®š
st.set_page_config(page_title="NHK News JLPT Analyzer", layout="wide")
st.title("ğŸ‡¯ğŸ‡µ NHK News JLPT å­¸ç¿’åˆ†æå™¨")

# 2. è¼‰å…¥è³‡æ–™
@st.cache_data
def load_data():
    # æ ¹æ“šç’°å¢ƒæ±ºå®šè®€å–å“ªä¸€ä»½è³‡æ–™åº«
    if os.getenv("GITHUB_ACTIONS"):
        file_path = "data/news_db.json"
    else:
        file_path = "data/news_db_test.json"

    if not os.path.exists(file_path):
        return pd.DataFrame()
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            # å°‡ JSON (Dict) è½‰ç‚º DataFrame ä»¥ä¾¿æ“ä½œï¼Œä¸¦è™•ç†ç©ºè³‡æ–™æƒ…æ³
            return pd.DataFrame.from_dict(data, orient='index') if data else pd.DataFrame()
    except Exception as e:
        print(f"âŒ è®€å–è³‡æ–™åº«å¤±æ•—: {e}")
        return pd.DataFrame()

@st.cache_data
def load_vocab():
    raw_url = "https://raw.githubusercontent.com/Bluskyo/JLPT_Vocabulary/main/data/results/JLPTWords.csv"
    
    try:
        with st.spinner('ğŸ“¡ æ­£åœ¨å¾ç·šä¸ŠåŒæ­¥ JLPT å…¨ç´šåˆ¥å­—å½™åº«...'):
            # ç›´æ¥è®€å–ç·šä¸Š CSV
            df = pd.read_csv(raw_url)
            
            # 1. å¼·åˆ¶æ¸…ç†æ¬„ä½åç¨±ï¼šå»é™¤é¦–å°¾ç©ºç™½ä¸¦è½‰ç‚ºå°å¯«
            # é€™æ¨£ç„¡è«– CSV æ˜¯ "Word" é‚„æ˜¯ "word" éƒ½èƒ½å°é½Š
            df.columns = df.columns.str.strip().str.lower()
            
            # 2. å®šç¾©å°æ‡‰é—œä¿‚ï¼ˆå°‡æˆ‘å€‘ä»£ç¢¼ç”¨çš„ 'word' å°æ‡‰åˆ° CSV çš„ 'word'ï¼‰
            # æ ¹æ“šä½ æä¾›çš„çµæ§‹ï¼Œæˆ‘å€‘éœ€è¦çš„æ˜¯ 'word' å’Œ 'jlptlevel'
            if 'word' in df.columns and 'jlptlevel' in df.columns:
                # é‡æ–°å‘½åä»¥ä¾¿å¾ŒçºŒä»£ç¢¼çµ±ä¸€ä½¿ç”¨
                df = df.rename(columns={'jlptlevel': 'level'})
            else:
                # è¬ä¸€æ¨™é¡Œå®Œå…¨å°ä¸ä¸Šï¼Œå›å‚³éŒ¯èª¤è¨Šæ¯
                st.error(f"âŒ CSV çµæ§‹ä¸ç¬¦ã€‚ç¾æœ‰æ¬„ä½: {list(df.columns)}")
                return pd.DataFrame(columns=['word', 'level'])
            
            # 3. æ•¸æ“šæ¸…æ´—
            df['word'] = df['word'].astype(str).str.strip()
            df['level'] = df['level'].astype(str).str.strip()
            
            # 4. æ ¼å¼æ¨™æº–åŒ–ï¼šç¢ºä¿ Level é¡¯ç¤ºç‚º N1, N2...
            # æœ‰äº›è³‡æ–™æœƒå­˜æˆ "1" æˆ– "n1"ï¼Œæˆ‘å€‘çµ±ä¸€è½‰æ›
            def format_level(lv):
                lv = lv.upper()
                return lv if lv.startswith('N') else f"N{lv}"
            
            df['level'] = df['level'].apply(format_level)
            
            # 5. ç§»é™¤é‡è¤‡é …ï¼Œç¢ºä¿æ¯å€‹å–®å­—åªæœ‰ä¸€å€‹é›£åº¦åˆ†ç´š
            df = df.drop_duplicates(subset=['word'], keep='first')
            
            return df[['word', 'level']]
            
    except Exception as e:
        st.error(f"âŒ ç·šä¸Šè©åº«è¼‰å…¥å¤±æ•—: {e}")
        return pd.DataFrame(columns=['word', 'level'])

df_news = load_data()
df_vocab = load_vocab()

# 3. å´é‚Šæ¬„ï¼šåŠŸèƒ½é¸å–®
st.sidebar.header("åŠŸèƒ½é¸å–®")
app_mode = st.sidebar.radio("è«‹é¸æ“‡æ¨¡å¼", ["NHK æ–°èé–±è®€", "è‡ªè¨‚æ–‡ç« åˆ†æ"])

if app_mode == "NHK æ–°èé–±è®€":
    if df_news.empty:
        st.warning("ç›®å‰æ²’æœ‰æ–°èè³‡æ–™ï¼Œè«‹å…ˆåŸ·è¡Œ `python sync_news.py` é€²è¡ŒåŒæ­¥ã€‚")
        st.stop()

    # æ ¹æ“š timestamp æ’åº (æœ€æ–°çš„åœ¨æœ€ä¸Šé¢)
    if 'timestamp' in df_news.columns:
        df_news = df_news.sort_values('timestamp', ascending=False)

    news_titles = df_news['title'].tolist()
    selected_title = st.sidebar.selectbox("è«‹é¸æ“‡ä¸€ç¯‡æ–°è", news_titles)
    current_article = df_news[df_news['title'] == selected_title].iloc[0]

    # --- æ ¸å¿ƒé‚è¼¯ï¼šå³æ™‚ç²å–å…§æ–‡ ---
    # å„ªå…ˆä½¿ç”¨è³‡æ–™åº«ä¸­çš„å…§å®¹ï¼Œå¦‚æœæ²’æœ‰æ‰å³æ™‚æŠ“å– (ç†è«–ä¸Š sync_news è·‘éå¾Œéƒ½æœƒæœ‰)
    if 'content' in current_article and current_article['content']:
        paragraphs = current_article['content']
    else:
        # å˜—è©¦å³æ™‚æŠ“å–ï¼Œä½†åœ¨ Streamlit Cloud ä¸Šå¯èƒ½æœƒå¤±æ•—ï¼Œéœ€åšéŒ¯èª¤è™•ç†
        try:
            paragraphs = fetch_article_full_text(current_article['url'])
        except Exception as e:
            st.error(f"âš ï¸ ç„¡æ³•è®€å–å…§æ–‡ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚(éŒ¯èª¤: {e})")
            paragraphs = []
            
    full_text = "".join(paragraphs) # ç”¨æ–¼ JLPT åˆ†æ

    # 4. ä¸»ç•«é¢ä½ˆå±€
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ“° æ–°èåŸæ–‡ (å®Œæ•´ç‰ˆ)")
        
        if 'translations' not in st.session_state:
            st.session_state.translations = {}

        for i, para in enumerate(paragraphs):
            st.write(para)
            # æ¯æ®µæä¾›ç¿»è­¯æŒ‰éˆ•
            if st.button(f"ç¿»è­¯ç¬¬ {i+1} æ®µ", key=f"btn_{i}"):
                with st.spinner("ç¿»è­¯ä¸­..."):
                    translated = translate_text(para)
                    st.session_state.translations[i] = translated
            
            if i in st.session_state.translations:
                st.info(st.session_state.translations[i])

    with col2:
        st.subheader("ğŸ“Š JLPT å…¨æ–‡é›£åº¦åˆ†æ")
        # ä½¿ç”¨å®Œæ•´çš„å…§æ–‡é€²è¡Œåˆ†æ
        level_stats = analyze_jlpt_level(full_text, df_vocab)
        
        fig = px.pie(values=level_stats.values, names=level_stats.index, 
                     title="å…¨æ–‡å–®å­—é›£åº¦åˆ†ä½ˆ",
                     color_discrete_sequence=px.colors.sequential.RdBu)
        st.plotly_chart(fig, width='stretch')
        
        # é¡¯ç¤ºæŒ‡æ¨™
        total_words = level_stats.sum()
        n3_up_ratio = (level_stats[['N1', 'N2', 'N3']].sum() / total_words * 100) if total_words > 0 else 0
        st.metric("N3 ä»¥ä¸Šé›£åº¦å æ¯”", f"{n3_up_ratio:.1f}%")

elif app_mode == "è‡ªè¨‚æ–‡ç« åˆ†æ":
    st.subheader("ğŸ“ è‡ªè¨‚æ–‡ç« åˆ†æ")
    user_text = st.text_area("è«‹åœ¨æ­¤è²¼ä¸Šæ—¥æ–‡æ–‡ç« ï¼š", height=300, placeholder="è«‹è¼¸å…¥æ—¥æ–‡æ–‡ç« ...")
    
    # åˆå§‹åŒ– Session State ä»¥æ”¯æ´äº’å‹• (å¦‚ç¿»è­¯)
    if 'custom_analysis_text' not in st.session_state:
        st.session_state.custom_analysis_text = ""
    if 'custom_translation' not in st.session_state:
        st.session_state.custom_translation = ""

    if st.button("é–‹å§‹åˆ†æ") and user_text:
        st.session_state.custom_analysis_text = user_text
        st.session_state.custom_translation = "" # é‡ç½®ç¿»è­¯

    if st.session_state.custom_analysis_text:
        target_text = st.session_state.custom_analysis_text
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("åŸæ–‡")
            st.write(target_text)
            
            if st.button("ç¿»è­¯å…¨æ–‡", key="btn_custom_trans"):
                with st.spinner("ç¿»è­¯ä¸­..."):
                    st.session_state.custom_translation = translate_text(target_text)
            
            if st.session_state.custom_translation:
                st.info(st.session_state.custom_translation)
            
        with col2:
            st.subheader("ğŸ“Š JLPT é›£åº¦åˆ†æ")
            level_stats = analyze_jlpt_level(target_text, df_vocab)
            
            fig = px.pie(values=level_stats.values, names=level_stats.index, 
                         title="å…¨æ–‡å–®å­—é›£åº¦åˆ†ä½ˆ",
                         color_discrete_sequence=px.colors.sequential.RdBu)
            st.plotly_chart(fig, width='stretch')
            
            total_words = level_stats.sum()
            n3_up_ratio = (level_stats[['N1', 'N2', 'N3']].sum() / total_words * 100) if total_words > 0 else 0
            st.metric("N3 ä»¥ä¸Šé›£åº¦å æ¯”", f"{n3_up_ratio:.1f}%")

st.divider()
st.caption("è³‡æ–™ä¾†æºï¼šNHK News Web. æœ¬ç³»çµ±åƒ…ä¾›å­¸ç¿’ä½¿ç”¨ã€‚")