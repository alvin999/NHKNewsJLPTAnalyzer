import streamlit as st
import pandas as pd
from app.translator import translate_text
from app.analyzer import analyze_jlpt_level
import plotly.express as px
from backend.crawl import fetch_article_full_text

# 1. é é¢è¨­å®š
st.set_page_config(page_title="NHK News JLPT Analyzer", layout="wide")
st.title("ğŸ‡¯ğŸ‡µ NHK News JLPT å­¸ç¿’åˆ†æå™¨")

# 2. è¼‰å…¥è³‡æ–™ (æ¨¡æ“¬è®€å– GitHub Actions æŠ“ä¸‹ä¾†çš„ CSV)
@st.cache_data
def load_data():
    # é€™è£¡è®€å–ä½  data/latest_articles.csv
    return pd.read_csv("data/latest_articles.csv")

@st.cache_data
def load_vocab():
    raw_url = "https://raw.githubusercontent.com/Bluskyo/JLPT_Vocabulary/main/data/results/JLPTWords.csv"
    
    try:
        with st.spinner('ğŸ“¡ æ­£åœ¨å¾ç·šä¸ŠåŒæ­¥ JLPT å…¨ç´šåˆ¥å­—å½™åº«...'):
            # ç›´æ¥è®€å–ç·šä¸Š CSV
            df = pd.read_csv(raw_url)
            
            # 1. å¼·åˆ¶æ¸…ç†æ¬„ä½åç¨±ï¼šå»é™¤é¦–å°¾ç©ºç™½ä¸¦è½‰ç‚ºå°å¯«
            # é€™æ¨£ç„¡è«– CSV æ˜¯ "Word" é‚„æ˜¯ "word" éƒ½èƒ½å°é½Š
            df.columns = df.columns.str.strip().str.lower()
            
            # 2. å®šç¾©å°æ‡‰é—œä¿‚ï¼ˆå°‡æˆ‘å€‘ä»£ç¢¼ç”¨çš„ 'word' å°æ‡‰åˆ° CSV çš„ 'word'ï¼‰
            # æ ¹æ“šä½ æä¾›çš„çµæ§‹ï¼Œæˆ‘å€‘éœ€è¦çš„æ˜¯ 'word' å’Œ 'jlptlevel'
            if 'word' in df.columns and 'jlptlevel' in df.columns:
                # é‡æ–°å‘½åä»¥ä¾¿å¾ŒçºŒä»£ç¢¼çµ±ä¸€ä½¿ç”¨
                df = df.rename(columns={'jlptlevel': 'level'})
            else:
                # è¬ä¸€æ¨™é¡Œå®Œå…¨å°ä¸ä¸Šï¼Œå›å‚³éŒ¯èª¤è¨Šæ¯
                st.error(f"âŒ CSV çµæ§‹ä¸ç¬¦ã€‚ç¾æœ‰æ¬„ä½: {list(df.columns)}")
                return pd.DataFrame(columns=['word', 'level'])
            
            # 3. æ•¸æ“šæ¸…æ´—
            df['word'] = df['word'].astype(str).str.strip()
            df['level'] = df['level'].astype(str).str.strip()
            
            # 4. æ ¼å¼æ¨™æº–åŒ–ï¼šç¢ºä¿ Level é¡¯ç¤ºç‚º N1, N2...
            # æœ‰äº›è³‡æ–™æœƒå­˜æˆ "1" æˆ– "n1"ï¼Œæˆ‘å€‘çµ±ä¸€è½‰æ›
            def format_level(lv):
                lv = lv.upper()
                return lv if lv.startswith('N') else f"N{lv}"
            
            df['level'] = df['level'].apply(format_level)
            
            # 5. ç§»é™¤é‡è¤‡é …ï¼Œç¢ºä¿æ¯å€‹å–®å­—åªæœ‰ä¸€å€‹é›£åº¦åˆ†ç´š
            df = df.drop_duplicates(subset=['word'], keep='first')
            
            return df[['word', 'level']]
            
    except Exception as e:
        st.error(f"âŒ ç·šä¸Šè©åº«è¼‰å…¥å¤±æ•—: {e}")
        return pd.DataFrame(columns=['word', 'level'])

df_news = load_data()
df_vocab = load_vocab()

# 3. å´é‚Šæ¬„ï¼šé¸æ“‡æ–°è
st.sidebar.header("æ–°èé¸æ“‡")
news_titles = df_news['title'].tolist()
selected_title = st.sidebar.selectbox("è«‹é¸æ“‡ä¸€ç¯‡æ–°è", news_titles)
current_article = df_news[df_news['title'] == selected_title].iloc[0]

# --- æ ¸å¿ƒé‚è¼¯ï¼šå³æ™‚ç²å–å…§æ–‡ ---
@st.cache_data(show_spinner="æ­£åœ¨æ“·å–æ—¥æœ¬ NHK å®Œæ•´å…§æ–‡...")
def get_full_content(url):
    return fetch_article_full_text(url)

paragraphs = get_full_content(current_article['url'])
full_text = "".join(paragraphs) # ç”¨æ–¼ JLPT åˆ†æ

# 4. ä¸»ç•«é¢ä½ˆå±€
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“° æ–°èåŸæ–‡ (å®Œæ•´ç‰ˆ)")
    
    if 'translations' not in st.session_state:
        st.session_state.translations = {}

    for i, para in enumerate(paragraphs):
        st.write(para)
        # æ¯æ®µæä¾›ç¿»è­¯æŒ‰éˆ•
        if st.button(f"ç¿»è­¯ç¬¬ {i+1} æ®µ", key=f"btn_{i}"):
            with st.spinner("ç¿»è­¯ä¸­..."):
                translated = translate_text(para)
                st.session_state.translations[i] = translated
        
        if i in st.session_state.translations:
            st.info(st.session_state.translations[i])

with col2:
    st.subheader("ğŸ“Š JLPT å…¨æ–‡é›£åº¦åˆ†æ")
    # ä½¿ç”¨å®Œæ•´çš„å…§æ–‡é€²è¡Œåˆ†æ
    level_stats = analyze_jlpt_level(full_text, df_vocab)
    
    fig = px.pie(values=level_stats.values, names=level_stats.index, 
                 title="å…¨æ–‡å–®å­—é›£åº¦åˆ†ä½ˆ",
                 color_discrete_sequence=px.colors.sequential.RdBu)
    st.plotly_chart(fig, width='stretch')
    
    # é¡¯ç¤ºæŒ‡æ¨™
    total_words = level_stats.sum()
    n3_up_ratio = (level_stats[['N1', 'N2', 'N3']].sum() / total_words * 100) if total_words > 0 else 0
    st.metric("N3 ä»¥ä¸Šé›£åº¦å æ¯”", f"{n3_up_ratio:.1f}%")

st.divider()
st.caption("è³‡æ–™ä¾†æºï¼šNHK News Web. æœ¬ç³»çµ±åƒ…ä¾›å­¸ç¿’ä½¿ç”¨ã€‚")