import pandas as pd
import os
import subprocess
import sys
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright
import urllib.request
import json

def fetch_nhk_news():
    api_url = "https://www3.nhk.or.jp/news/json16/new_001.json"
    
    # ä½¿ç”¨æœ€æ¥µç°¡ä½†æœ‰æ•ˆçš„ Headers
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/121.0.0.0 Safari/537.36',
        'Accept': 'application/json',
        'Accept-Language': 'ja-JP,ja;q=0.9'
    }
    
    try:
        req = urllib.request.Request(api_url, headers=headers)
        # é€™è£¡ä¸ä½¿ç”¨ HTTP/2ï¼Œç›´æ¥èµ°æ¨™æº– HTTP/1.1 ä¸²æµ
        with urllib.request.urlopen(req, timeout=15) as response:
            if response.status == 200:
                data = json.loads(response.read().decode('utf-8'))
                items = data.get('channel', {}).get('item', [])
                
                articles = []
                for item in items:
                    raw_link = item.get('link', '')
                    full_id = raw_link.split('/')[-1].replace('.html', '')
                    na_url = f"https://news.web.nhk/newsweb/na/na-{full_id}"
                    
                    articles.append({
                        'id': item.get('id'),
                        'title': item.get('title'),
                        'url': na_url
                    })
                return pd.DataFrame(articles)
            else:
                print(f"âŒ ä¼ºæœå™¨å›å‚³ç‹€æ…‹ç¢¼: {response.status}")
                return pd.DataFrame()
                
    except Exception as e:
        print(f"âŒ urllib æŠ“å–å¤±æ•—: {e}")
        return pd.DataFrame()

def fetch_article_full_text(url):
    try:
        with sync_playwright() as p:
            # 1. æ¨¡æ“¬ Codegen çš„å•Ÿå‹•ç’°å¢ƒ
            try:
                # æ”¹ç”¨ headless=True ä¸¦åŠ å…¥ååµæ¸¬åƒæ•¸
                browser = p.chromium.launch(
                    headless=True,
                    args=[
                        "--headless=new",  # é—œéµï¼šä½¿ç”¨æ–°ç‰ˆ Headless æ¨¡å¼ï¼Œè¡Œç‚ºæ›´åƒçœŸå¯¦ç€è¦½å™¨
                        "--disable-blink-features=AutomationControlled", # é—œéµï¼šéš±è— navigator.webdriver æ¨™è¨˜
                        "--no-sandbox",
                        "--disable-dev-shm-usage", # é˜²æ­¢è¨˜æ†¶é«”ä¸è¶³å´©æ½°
                        "--disable-extensions",
                        "--disable-gpu",
                        "--disable-infobars"
                    ]
                )
            except Exception as e:
                # å¦‚æœé‡åˆ°ç€è¦½å™¨æœªå®‰è£çš„éŒ¯èª¤ï¼Œå˜—è©¦è‡ªå‹•å®‰è£
                if "Executable doesn't exist" in str(e):
                    print("âš ï¸ åµæ¸¬åˆ°ç€è¦½å™¨æœªå®‰è£ï¼Œæ­£åœ¨è‡ªå‹•åŸ·è¡Œ playwright install chromium...")
                    subprocess.check_call([sys.executable, "-m", "playwright", "install", "chromium"])
                    browser = p.chromium.launch(headless=True, args=["--headless=new", "--disable-blink-features=AutomationControlled"])
                else:
                    raise e

            context = browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                locale='ja-JP',
                timezone_id='Asia/Tokyo',
                geolocation={'latitude': 35.6895, 'longitude': 139.6917}, # ğŸ“ è¨­å®šç‚ºæ—¥æœ¬æ±äº¬åº§æ¨™
                permissions=['geolocation'], # âœ… å…è¨±ç¶²ç«™ç²å–ä½ç½®è³‡è¨Š (å¢åŠ çœŸå¯¦æ„Ÿ)
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
            )
            
            # ğŸ•µï¸â€â™‚ï¸ æ³¨å…¥ Stealth è…³æœ¬ï¼šå¾¹åº•éš±è—è‡ªå‹•åŒ–ç‰¹å¾µ
            context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            """)
            
            page = context.new_page()
            
            
            # 2. å‰å¾€ç¶²å€
            page.goto(url, wait_until="domcontentloaded")


            # --- é—œéµä¿®æ­£ï¼šåƒ Codegen ä¸€æ¨£éˆæ´»æ‡‰å° ---
            # æœ‰äº›ç’°å¢ƒæœƒè·³å‡º 1/2 å±¤ï¼Œæœ‰äº›ç›´æ¥è·³ 3 å±¤ã€‚æˆ‘å€‘ç”¨ try-except åŒ…èµ·ä¾†ã€‚
            
            # å˜—è©¦æ“Šç©¿ç¬¬ 1 & 2 å±¤ (å¦‚æœæœ‰çš„è©±)
            try:
                if page.get_by_text("å†…å®¹ã«ã¤ã„ã¦ç¢ºèªã—ã¾ã—ãŸ").is_visible(timeout=1000):
                    page.get_by_text("å†…å®¹ã«ã¤ã„ã¦ç¢ºèªã—ã¾ã—ãŸ").click()
                    page.get_by_role("button", name="æ¬¡ã¸").click()
                    page.wait_for_timeout(1000)
                    
                    # è™•ç† 2/2 å€åŸŸé¸æ“‡
                    page.get_by_label("ä¸–å¸¯(å€‹äºº)ã§").check()
                    page.locator("select").select_option(index=1)
                    page.get_by_role("button", name="ã‚µãƒ¼ãƒ“ã‚¹ã®åˆ©ç”¨ã‚’é–‹å§‹ã™ã‚‹").click()
                    print("âœ… æ“Šç©¿å‰å…©å±¤å°è¦½")
            except:
                print("â„¹ï¸ æœªåµæ¸¬åˆ°å‰å…©å±¤ï¼Œå¯èƒ½å·²è·³é")
            # 3. æ“Šç©¿ç¬¬ä¸‰å±¤ (Codegen éŒ„åˆ°çš„é‚£ä¸€æ­¥)
            try:
                # å®šç¾©å®šä½å™¨ï¼šæ–‡å­— èˆ‡ Class (å¢åŠ å®¹éŒ¯)
                btn_text = page.get_by_role("button", name="ç¢ºèªã—ã¾ã—ãŸ / I understand")
                btn_class = page.locator("button.esl7kn2s")
                
                target_btn = None
                
                # æ”¹ç‚ºé‚Šæ²å‹•é‚Šåµæ¸¬ï¼Œæ¨¡æ“¬çœŸäººé–±è®€ä¸¦è§¸ç™¼æŒ‰éˆ•é¡¯ç¤º
                for _ in range(5):
                    if btn_text.is_visible():
                        target_btn = btn_text
                        break
                    if btn_class.is_visible():
                        target_btn = btn_class
                        break
                    page.mouse.wheel(0, 1000) # æ¯æ¬¡å‘ä¸‹æ²å‹• 1000px

                    page.wait_for_timeout(1000) # ç­‰å¾… 1 ç§’è®“å…§å®¹è¼‰å…¥
                
                # å¦‚æœé‚„æ²’æ‰¾åˆ°ï¼Œæœ€å¾Œè©¦ä¸€æ¬¡ç›´æ¥åˆ°åº•
                if not target_btn:
                    page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    page.wait_for_timeout(1000)
                    if btn_text.is_visible(): target_btn = btn_text
                    elif btn_class.is_visible(): target_btn = btn_class

                if target_btn:
                    target_btn.scroll_into_view_if_needed()
                    target_btn.click(force=True)
                    print("âœ… æˆåŠŸåŸ·è¡Œ Codegen éŒ„è£½çš„é»æ“Šï¼šç¢ºèªã—ã¾ã—ãŸ / I understand")

                    # é—œéµä¿®æ­£ï¼šé»æ“Šå¾Œé é¢æœƒåˆ·æ–°æˆ–å°èˆªï¼Œå¿…é ˆç­‰å¾…è¼‰å…¥å®Œæˆ
                    page.wait_for_load_state("domcontentloaded")
                    page.wait_for_timeout(2000)
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•é»æ“Šç¬¬ä¸‰å±¤æŒ‰éˆ•: {e}")

            # æ“·å–å…§æ–‡
            html_content = page.content()
            browser.close()
            
            soup = BeautifulSoup(html_content, 'html.parser')
            # æŠ“å–æ–°ç‰ˆå…§æ–‡æ¨™ç±¤
            nodes = soup.find_all(['p', 'h3'], class_=['_1i1d7sh2', '_1i1d7sh9'])
            return [n.get_text().strip() for n in nodes if n.get_text().strip()]

    except Exception as e:
        print(f"âŒ åŸ·è¡Œå¤±æ•—: {e}")
        return []

# --- æ¸¬è©¦èˆ‡åŸ·è¡Œå€å¡Š ---
if __name__ == "__main__":
    print("ğŸ“¡ æ­£åœ¨å˜—è©¦æŠ“å– NHK æœ€æ–°æ–°è...")
    
    df = fetch_nhk_news()
    
    if not df.empty:
        os.makedirs('data', exist_ok=True)
        # å„²å­˜æ¸…å–®
        df.to_csv('data/latest_articles.csv', index=False, encoding='utf-8-sig')
        print(f"âœ… æˆåŠŸï¼æŠ“å–åˆ° {len(df)} å‰‡æ–°èæ¸…å–®ã€‚")
        
        # æ¸¬è©¦æŠ“å–ç¬¬ä¸€å‰‡çš„å…¨æ–‡
        first_url = df.iloc[0]['url']
        print(f"ğŸ” æ¸¬è©¦æŠ“å–ç¬¬ä¸€å‰‡å…¨æ–‡: {first_url}")
        content = fetch_article_full_text(first_url)
        print(f"ğŸ“ å…§æ–‡æ®µè½æ•¸: {len(content)}")
        for i, p in enumerate(content[:3]): # å°å‡ºå‰ä¸‰æ®µçœ‹çœ‹
            print(f"  æ®µè½ {i+1}: {p[:50]}...")
    else:
        print("âŒ ä¾ç„¶ç„¡æ³•æŠ“å–è³‡æ–™ï¼Œè«‹æª¢æŸ¥ JSON çµæ§‹ã€‚")